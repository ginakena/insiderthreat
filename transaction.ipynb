{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technique: Baseline, X_processed shape: (284850, 10, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping One-Hot Encoding due to shape mismatch: (284850, 10, 4) vs (984, 984)\n",
      "Technique: Standardization, X_processed shape: (284850, 10, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The target 'y' needs to have more than 1 class. Got 1 class instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 89\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m technique \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     88\u001b[0m     smote \u001b[38;5;241m=\u001b[39m SMOTE()\n\u001b[1;32m---> 89\u001b[0m     X_processed, _ \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     X_processed \u001b[38;5;241m=\u001b[39m X_processed\u001b[38;5;241m.\u001b[39mreshape(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], seq_length, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# ✅ Fix reshape\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m technique \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Selection\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:202\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:101\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m     98\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m     99\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_sampling_strategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampling_type\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    107\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    109\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\utils\\_validation.py:537\u001b[0m, in \u001b[0;36mcheck_sampling_strategy\u001b[1;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_type\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSAMPLING_KIND\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m     )\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(y)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe target \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m needs to have more than 1 class. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39munique(y)\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m class instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m     )\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sampling_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensemble\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbypass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sampling_strategy\n",
      "\u001b[1;31mValueError\u001b[0m: The target 'y' needs to have more than 1 class. Got 1 class instead"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"transactions.csv\"  # Update this path if needed\n",
    "transactions_df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert date to timestamp\n",
    "transactions_df['date'] = pd.to_datetime(transactions_df['date'])\n",
    "transactions_df['timestamp'] = transactions_df['date'].astype(np.int64) // 10**9\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "transactions_df[['transaction_dollar_amount', 'Long', 'Lat', 'timestamp']] = scaler.fit_transform(\n",
    "    transactions_df[['transaction_dollar_amount', 'Long', 'Lat', 'timestamp']]\n",
    ")\n",
    "\n",
    "# Sort transactions by credit card and timestamp\n",
    "transactions_df = transactions_df.sort_values(by=['credit_card', 'timestamp'])\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, seq_length=10):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data.iloc[i:i + seq_length].values\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "# Create sequences per credit card\n",
    "seq_length = 10  # Use 10 past transactions per sequence\n",
    "all_sequences = []\n",
    "for _, group in transactions_df.groupby('credit_card'):\n",
    "    sequences = create_sequences(group[['transaction_dollar_amount', 'Long', 'Lat', 'timestamp']], seq_length)\n",
    "    all_sequences.extend(sequences)\n",
    "X_train = np.array(all_sequences)\n",
    "\n",
    "# Define LSTM Autoencoder model\n",
    "def build_lstm_autoencoder(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, activation=\"relu\", input_shape=input_shape, return_sequences=True),\n",
    "        LSTM(32, activation=\"relu\", return_sequences=False),\n",
    "        RepeatVector(input_shape[0]),\n",
    "        LSTM(32, activation=\"relu\", return_sequences=True),\n",
    "        LSTM(64, activation=\"relu\", return_sequences=True),\n",
    "        TimeDistributed(Dense(input_shape[1]))\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# List of preprocessing techniques\n",
    "techniques = [\"Baseline\", \"One-Hot Encoding\", \"Standardization\", \"SMOTE\", \"Feature Selection\", \"PCA\"]\n",
    "accuracies = []\n",
    "\n",
    "for technique in techniques:\n",
    "    X_processed = X_train.copy()\n",
    "\n",
    "    if technique == \"Baseline\":\n",
    "        pass\n",
    "    \n",
    "    elif technique == \"One-Hot Encoding\":\n",
    "        encoder = OneHotEncoder()\n",
    "        encoded_cards = encoder.fit_transform(transactions_df[['credit_card']]).toarray()\n",
    "\n",
    "        # Assign each sequence the encoding of its first transaction's credit_card\n",
    "        first_indices = transactions_df.groupby('credit_card').head(1).index\n",
    "        encoded_sequences = np.array([encoded_cards[i] for i in first_indices if i < len(encoded_cards)])\n",
    "\n",
    "        # Ensure shape consistency before concatenation\n",
    "        if X_train.shape[0] == encoded_sequences.shape[0]:\n",
    "            X_processed = np.hstack([X_train.reshape(X_train.shape[0], -1), encoded_sequences])\n",
    "        else:\n",
    "            print(f\"Skipping One-Hot Encoding due to shape mismatch: {X_train.shape} vs {encoded_sequences.shape}\")\n",
    "            continue\n",
    "\n",
    "    elif technique == \"Standardization\":\n",
    "        scaler = StandardScaler()\n",
    "        X_processed = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "        X_processed = X_processed.reshape(X_train.shape[0], seq_length, -1)  # ✅ Fix reshape\n",
    "\n",
    "   elif technique == \"SMOTE\":\n",
    "    smote = SMOTE()\n",
    "    \n",
    "    # Use fraud labels if available, else generate synthetic ones\n",
    "    if 'fraud' in transactions_df.columns:\n",
    "        y = transactions_df['fraud'].values  # Ensure there are both 0s and 1s\n",
    "    else:\n",
    "        y = np.random.choice([0, 1], size=X_train.shape[0], p=[0.95, 0.05])  # Simulate imbalance\n",
    "\n",
    "    if len(np.unique(y)) < 2:\n",
    "        print(\"Skipping SMOTE: Not enough classes in y\")\n",
    "        continue\n",
    "\n",
    "    X_processed, y_resampled = smote.fit_resample(X_train.reshape(X_train.shape[0], -1), y)\n",
    "    \n",
    "    # Reshape back to LSTM format\n",
    "    X_processed = X_processed.reshape(X_processed.shape[0], seq_length, -1)\n",
    "\n",
    "\n",
    "    elif technique == \"Feature Selection\":\n",
    "        X_processed = X_train[:, :, :3]  # Select first 3 features\n",
    "\n",
    "    elif technique == \"PCA\":\n",
    "        pca = PCA(n_components=3)\n",
    "        X_flattened = X_train.reshape(X_train.shape[0], -1)\n",
    "        X_pca = pca.fit_transform(X_flattened)\n",
    "        \n",
    "        try:\n",
    "            X_processed = X_pca.reshape(X_train.shape[0], seq_length, -1)  # ✅ Fix reshape\n",
    "        except ValueError:\n",
    "            print(f\"Skipping PCA due to reshaping error: {X_pca.shape}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Technique: {technique}, X_processed shape: {X_processed.shape}\")\n",
    "\n",
    "    # **Fix LSTM Model Input Shape**\n",
    "    model = build_lstm_autoencoder((seq_length, X_processed.shape[2]))  # ✅ Pass correct feature dimension\n",
    "    history = model.fit(X_processed, X_processed, epochs=5, batch_size=128, validation_split=0.1, verbose=0)\n",
    "\n",
    "    loss = model.evaluate(X_processed, X_processed, verbose=0)\n",
    "    accuracy = 1 - loss\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "\n",
    "# Plot accuracy comparison as a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(accuracies, labels=techniques, autopct=\"%.1f%%\", startangle=140, colors=[\"#ff9999\", \"#66b3ff\", \"#99ff99\", \"#ffcc99\", \"#c2c2f0\", \"#ffb3e6\"])\n",
    "plt.title(\"Accuracy Comparison of Preprocessing Techniques\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
